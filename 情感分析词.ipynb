{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第1页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=0&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                              | 1/20 [00:05<01:36,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第2页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=10&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:10<01:31,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第3页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=20&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [00:14<01:22,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第4页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=30&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [00:18<01:14,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第5页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=40&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [00:22<01:05,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第6页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=50&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [00:26<00:58,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第7页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=60&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [00:30<00:55,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第8页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=70&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:34<00:48,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第9页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=80&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:37<00:43,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第10页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=90&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:41<00:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第11页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=100&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:45<00:36,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第12页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=110&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:49<00:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第13页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=120&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:54<00:28,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第14页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=130&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [00:59<00:26,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第15页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=140&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [01:04<00:22,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第16页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=150&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [01:08<00:18,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第17页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=160&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [01:13<00:14,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第18页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=170&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [01:17<00:08,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第19页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=180&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [01:21<00:04,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第20页短评爬取成功！\n",
      "https://movie.douban.com/subject/30166972/comments?start=190&limit=20&sort=new_score&status=P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:26<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "name_list, content_list, date_list, score_list, city_list = [], [], [], [], []\n",
    "movie_name = \"\"\n",
    "\n",
    "\n",
    "def get_content(id, page):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'}\n",
    "    url = \"https://movie.douban.com/subject/\" + str(id) + \"/comments?start=\" + str(page * 10) + \"&limit=20&sort=new_score&status=P\"\n",
    "    res = requests.get(url, headers=headers)\n",
    "\n",
    "    pattern = re.compile('<div id=\"wrapper\">.*?<div id=\"content\">.*?<h1>(.*?) 短评</h1>', re.S)\n",
    "    global movie_name\n",
    "    movie_name = re.findall(pattern, res.text)[0]  # list类型\n",
    "\n",
    "    res.encoding = \"utf-8\"\n",
    "    #res = res.encode(\"utf-8\").decode(\"latin1\")\n",
    "    if (res.status_code == 200):\n",
    "        print(\"\\n第{}页短评爬取成功！\".format(page + 1))\n",
    "        print(url)\n",
    "    else:\n",
    "        print(\"\\n第{}页爬取失败！\".format(page + 1))\n",
    "\n",
    "    with open('html.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(res.text)\n",
    "        f.close()\n",
    "    x = etree.HTML(res.text)\n",
    "    for i in range(1, 21):   # 每页20个评论用户\n",
    "        name = x.xpath('//*[@id=\"comments\"]/div[{}]/div[2]/h3/span[2]/a/text()'.format(i))\n",
    "        \n",
    "        score = x.xpath('//*[@id=\"comments\"]/div[{}]/div[2]/h3/span[2]/span[2]/@title'.format(i))\n",
    "        date = x.xpath('//*[@id=\"comments\"]/div[{}]/div[2]/h3/span[2]/span[3]/@title'.format(i))\n",
    "        m = '\\d{4}-\\d{2}-\\d{2}'\n",
    "        try:\n",
    "            match = re.compile(m).match(score[0])\n",
    "        except IndexError:\n",
    "            break\n",
    "        if match is not None:\n",
    "            date = score\n",
    "            score = [\"null\"]\n",
    "        else:\n",
    "            pass\n",
    "        content = x.xpath('//*[@id=\"comments\"]/div[{}]/div[2]/p/span/text()'.format(i))\n",
    "        id = x.xpath('//*[@id=\"comments\"]/div[{}]/div[2]/h3/span[2]/a/@href'.format(i))\n",
    "        name_list.append(str(name[0]))\n",
    "        score_list.append(str(score[0]).strip('[]\\''))  \n",
    "        date_list.append(str(date[0]).strip('[\\'').split(' ')[0])\n",
    "        content_list.append(str(content[0]).strip())\n",
    "\n",
    "\n",
    "def main(ID, pages):\n",
    "    global movie_name\n",
    "    for i in tqdm(range(0, pages)): \n",
    "        get_content(ID, i)  # 第一个参数是豆瓣电影对应的id序号，第二个参数是想爬取的评论页数\n",
    "        time.sleep(round(random.uniform(3, 5), 2))\n",
    "    infos = {'name': name_list,  'content': content_list, 'score': score_list, 'date': date_list}\n",
    "    data = pd.DataFrame(infos, columns=['name', 'content', 'score', 'date'])\n",
    "    data.to_csv(movie_name + \".csv\")  # 存储名为  电影名.csv\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(30166972, 20)  # 评论电影的ID号+要爬取的评论页面数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  star\n",
       "0  面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...     4\n",
       "1  曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...     4\n",
       "2                        经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场     4\n",
       "3  对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐     5\n",
       "4                    恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('comment.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['star'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  star  sentiment\n",
       "0  面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...     4          1\n",
       "1  曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...     4          1\n",
       "2                        经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场     4          1\n",
       "3  对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐     5          1\n",
       "4                    恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐     5          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_label(star):\n",
    "    if star > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data['sentiment'] = data.star.apply(make_label)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\asus\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "data['cut_comment'] = data.comment.apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>面对 坠楼 ， 他们 忙 着 拍照 发微信 ， 只有 她 为 她 盖 上 衣服 。 面对 欺...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>曾国祥 好 得 有点 不能 理解 了 ， 他 是 用 什么 意识 拍 出 模拟考试 结束 后...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>经历 过 校园 霸凌 的 人 很 难 走 出来 ， 但 可以 在 电影 里 好好 哭 一场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>对易 烊 千玺 本来 是 路 人 的 ， 但是 被 他 演技 惊到 了 … 真的 ， 演 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>恶意 就是 这样 的 ， 无端 的 针对 一个 人 ， 即使 别人 没有 做错 什么 。 , 力荐</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  star  sentiment  \\\n",
       "0  面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...     4          1   \n",
       "1  曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...     4          1   \n",
       "2                        经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场     4          1   \n",
       "3  对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐     5          1   \n",
       "4                    恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐     5          1   \n",
       "\n",
       "                                         cut_comment  \n",
       "0  面对 坠楼 ， 他们 忙 着 拍照 发微信 ， 只有 她 为 她 盖 上 衣服 。 面对 欺...  \n",
       "1  曾国祥 好 得 有点 不能 理解 了 ， 他 是 用 什么 意识 拍 出 模拟考试 结束 后...  \n",
       "2      经历 过 校园 霸凌 的 人 很 难 走 出来 ， 但 可以 在 电影 里 好好 哭 一场  \n",
       "3  对易 烊 千玺 本来 是 路 人 的 ， 但是 被 他 演技 惊到 了 … 真的 ， 演 的...  \n",
       "4  恶意 就是 这样 的 ， 无端 的 针对 一个 人 ， 即使 别人 没有 做错 什么 。 , 力荐  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cut_comment']\n",
    "y = data.sentiment\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file,encoding='UTF-8') as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list\n",
    "    stopwords.close()\n",
    "\n",
    "stop_words_file = '停用词.txt'\n",
    "stopwords = get_custom_stopwords(stop_words_file)\n",
    "\n",
    "vect = CountVectorizer(max_df = 0.8, \n",
    "                       min_df = 3, \n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>days</th>\n",
       "      <th>dd</th>\n",
       "      <th>ost</th>\n",
       "      <th>ps</th>\n",
       "      <th>一丝</th>\n",
       "      <th>一刻</th>\n",
       "      <th>一回</th>\n",
       "      <th>一场</th>\n",
       "      <th>一如既往</th>\n",
       "      <th>...</th>\n",
       "      <th>音效</th>\n",
       "      <th>顶光</th>\n",
       "      <th>预售</th>\n",
       "      <th>预期</th>\n",
       "      <th>题材</th>\n",
       "      <th>首映</th>\n",
       "      <th>高考</th>\n",
       "      <th>黄鸭</th>\n",
       "      <th>黑夜</th>\n",
       "      <th>黑暗</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 733 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  days  dd  ost  ps  一丝  一刻  一回  一场  一如既往 ...  音效  顶光  预售  预期  题材  \\\n",
       "0       0     0   0    0   0   0   0   0   0     0 ...   0   0   0   0   0   \n",
       "1       0     0   0    0   0   0   0   0   0     0 ...   0   0   0   0   0   \n",
       "2       0     0   0    0   0   0   0   0   0     0 ...   0   0   0   0   0   \n",
       "3       0     0   0    0   0   0   0   0   0     0 ...   0   0   0   0   0   \n",
       "4       0     0   0    0   0   0   0   0   0     0 ...   0   0   0   0   0   \n",
       "\n",
       "   首映  高考  黄鸭  黑夜  黑暗  \n",
       "0   0   0   0   0   0  \n",
       "1   0   0   0   0   0  \n",
       "2   0   0   0   0   0  \n",
       "3   0   0   0   0   0  \n",
       "4   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 733 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933993399339934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "nb.fit(X_train_vect, y_train)\n",
    "train_score = nb.score(X_train_vect, y_train)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9868421052631579\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(nb.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec = vect.transform(X)\n",
    "nb_result = nb.predict(X_vec)\n",
    "data['nb_result'] = nb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_comment</th>\n",
       "      <th>nb_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>面对 坠楼 ， 他们 忙 着 拍照 发微信 ， 只有 她 为 她 盖 上 衣服 。 面对 欺...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>曾国祥 好 得 有点 不能 理解 了 ， 他 是 用 什么 意识 拍 出 模拟考试 结束 后...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>经历 过 校园 霸凌 的 人 很 难 走 出来 ， 但 可以 在 电影 里 好好 哭 一场</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>对易 烊 千玺 本来 是 路 人 的 ， 但是 被 他 演技 惊到 了 … 真的 ， 演 的...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>恶意 就是 这样 的 ， 无端 的 针对 一个 人 ， 即使 别人 没有 做错 什么 。 , 力荐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  star  sentiment  \\\n",
       "0  面对坠楼，他们忙着拍照发微信，只有她为她盖上衣服。面对欺凌，他们假装没看见，只有她选择报警。...     4          1   \n",
       "1  曾国祥好得有点不能理解了，他是用什么意识拍出模拟考试结束后全班按分数重新排座位然后整个班级在...     4          1   \n",
       "2                        经历过校园霸凌的人很难走出来，但可以在电影里好好哭一场     4          1   \n",
       "3  对易烊千玺本来是路人的，但是被他演技惊到了…真的，演的好，和周冬雨对视那场戏，我也跟着哭了。,力荐     5          1   \n",
       "4                    恶意就是这样的，无端的针对一个人，即使别人没有做错什么。,力荐     5          1   \n",
       "\n",
       "                                         cut_comment  nb_result  \n",
       "0  面对 坠楼 ， 他们 忙 着 拍照 发微信 ， 只有 她 为 她 盖 上 衣服 。 面对 欺...          1  \n",
       "1  曾国祥 好 得 有点 不能 理解 了 ， 他 是 用 什么 意识 拍 出 模拟考试 结束 后...          1  \n",
       "2      经历 过 校园 霸凌 的 人 很 难 走 出来 ， 但 可以 在 电影 里 好好 哭 一场          1  \n",
       "3  对易 烊 千玺 本来 是 路 人 的 ， 但是 被 他 演技 惊到 了 … 真的 ， 演 的...          1  \n",
       "4  恶意 就是 这样 的 ， 无端 的 针对 一个 人 ， 即使 别人 没有 做错 什么 。 , 力荐          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snownlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-62912551aac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msnownlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowNLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtext1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'这个东西不错'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'这个东西很垃圾'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowNLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ms2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowNLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'snownlp'"
     ]
    }
   ],
   "source": [
    "from snownlp import SnowNLP \n",
    "text1 = '这个东西不错' \n",
    "text2 = '这个东西很垃圾' \n",
    "s1 = SnowNLP(text1) \n",
    "s2 = SnowNLP(text2) \n",
    "print(s1.sentiments,s2.sentiments) \n",
    "# result 0.8623218777387431 0.21406279508712744 \n",
    " \n",
    "def snow_result(comemnt): \n",
    "    s = SnowNLP(comemnt) \n",
    "    if s.sentiments >= 0.6: \n",
    "        return 1 \n",
    "    else: \n",
    "        return 0 \n",
    "data['snlp_result'] = data.comment.apply(snow_result) \n",
    "\n",
    "counts = 0 \n",
    "for i in range(len(data)): \n",
    "    if data.iloc[i,2] == data.iloc[i,3]: \n",
    "        counts+=1 \n",
    "    print(counts/len(data)) \n",
    "# result 0.763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
